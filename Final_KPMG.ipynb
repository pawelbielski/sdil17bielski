{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's list all the files in the RawData folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BSAD.csv', 'BSAK.csv', 'EKBE.csv', 'EKKO.csv', 'EKPO.csv', 'KNA1.csv', 'LFA1.csv', 'LFB1.csv', 'LFBK.csv', 'MAKT.csv', 'MARDH.csv', 'MBEWH.csv', 'RBKP.csv', 'REGUH.csv', 'REGUP.csv', 'RSEG.csv', 'T001.csv', 'T001K.csv', 'T001W.csv', 'USER_ADDR.csv', 'VBRK.csv', 'VBRP.csv']\n"
     ]
    }
   ],
   "source": [
    "data_path = 'Datensatz/RawData'\n",
    "\n",
    "file_names = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "sorted_file_names = sorted(file_names)\n",
    "\n",
    "print(sorted_file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Decistion Tree Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_dt(X, y):\n",
    "    \n",
    "    TPR_all = []\n",
    "    FPR_all = []\n",
    "    FNR_all = []\n",
    "    prec_all = []\n",
    "    f1_all = []    \n",
    "\n",
    "    dt = DecisionTreeClassifier(max_depth=2, random_state=11)\n",
    "    kf = KFold(n_splits=10, random_state=11, shuffle=False)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        \n",
    "        dt.fit(X.loc[train_index], y.loc[train_index])\n",
    "        \n",
    "        y_pred = dt.predict(X.loc[test_index])\n",
    "        \n",
    "        #scores\n",
    "        cm = confusion_matrix(y.iloc[test_index], y_pred, labels=[1, 0])\n",
    "        \n",
    "        TN = cm[0][0]\n",
    "        FN = cm[1][0]\n",
    "        TP = cm[1][1]\n",
    "        FP = cm[0][1]\n",
    "        \n",
    "        \n",
    "        TPR_all.append(float(TP)/(TP + FN))\n",
    "        FPR_all.append(float(FP)/(FP + TN))\n",
    "        FNR_all.append(float(FN)/(FN + TP))\n",
    "        \n",
    "        prec_all.append(precision_score(y.loc[test_index], y_pred))\n",
    "        f1_all.append(f1_score(y.loc[test_index], y_pred))\n",
    "        \n",
    "    print('TPR: {}'.format(np.mean(TPR_all)))\n",
    "    print('FPR: {}'.format(np.mean(FPR_all)))\n",
    "    print('FNR: {}'.format(np.mean(FNR_all)))\n",
    "    print('Prec: {}'.format(np.mean(prec_all)))\n",
    "    print('F1: {}'.format(np.mean(f1_all)))\n",
    "    \n",
    "def evaluate_dt_split(X, y):\n",
    "    \n",
    "    TPR_all = []\n",
    "    FPR_all = []\n",
    "    FNR_all = []\n",
    "    prec_all = []\n",
    "    f1_all = []\n",
    "\n",
    "    dt = DecisionTreeClassifier(max_depth=2, random_state=11)\n",
    "    \n",
    "        \n",
    "    train_index, test_index = train_test_split(X.index.values.tolist(), random_state= 11)\n",
    "        \n",
    "    dt.fit(X.loc[train_index], y.loc[train_index])\n",
    "\n",
    "    y_pred = dt.predict(X.loc[test_index])\n",
    "\n",
    "    #scores\n",
    "    cm = confusion_matrix(y.iloc[test_index], y_pred)\n",
    "\n",
    "    TN = cm[0][0]\n",
    "    FN = cm[1][0]\n",
    "    TP = cm[1][1]\n",
    "    FP = cm[0][1]\n",
    "\n",
    "    \n",
    "    TPR_all.append(float(TP)/(TP + FN))\n",
    "    FPR_all.append(float(FP)/(FP + TN))\n",
    "    FNR_all.append(float(FN)/(FN + TP))\n",
    "\n",
    "    prec_all.append(precision_score(y.loc[test_index], y_pred, pos_label=1))\n",
    "    f1_all.append(f1_score(y.loc[test_index], y_pred, pos_label=1))\n",
    "        \n",
    "        \n",
    "    print('TN:{}'.format(TN))\n",
    "    print('FN:{}'.format(FN))\n",
    "    print('TP:{}'.format(TP))\n",
    "    print('FP:{}'.format(FP))\n",
    "    \n",
    "    print('TPR: {}'.format(np.mean(TPR_all)))\n",
    "    print('FPR: {}'.format(np.mean(FPR_all)))\n",
    "    print('FNR: {}'.format(np.mean(FNR_all)))\n",
    "    print('Prec: {}'.format(np.mean(prec_all)))\n",
    "    print('F1: {}'.format(np.mean(f1_all)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 13)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfa = pd.read_csv(join(data_path, 'LFA1.csv'), sep=';', encoding = 'ISO-8859-1')\n",
    "lfa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9997, 6)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfbk = pd.read_csv(join(data_path, 'LFBK.csv'), sep=';', encoding = 'ISO-8859-1', quoting=3)\n",
    "lfbk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 17)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pd.merge(lfa,lfbk, how='left', on=['LIFNR','MANDT'])\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12634, 5)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfb = pd.read_csv(join(data_path, 'LFB1.csv'), sep=';', encoding = 'ISO-8859-1', quoting=3)\n",
    "lfb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10008, 20)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = pd.merge(m,lfb[lfb['BUKRS']==1000], how='left', on=['LIFNR','MANDT'])\n",
    "m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9950, 20)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = m2[pd.notnull(m2['CASE1']) & pd.notnull(m2['CASE2']) & pd.notnull(m2['ERDAT_y'])]\n",
    "m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2['NAME1'] = m2['NAME1'].astype(str)\n",
    "m2['KOINH'] = m2['KOINH'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9950, 22)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2['FEAT'] = m2.apply(lambda x: x.KOINH[1:] in x.NAME1 , axis=1).astype(int)\n",
    "m2['FEAT2'] = m2.apply(lambda x: x.ERDAT_x != x.ERDAT_y , axis=1).astype(int)\n",
    "m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m2 = m2.reset_index(drop=True)\n",
    "#m2 = m2.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_cols = ['FEAT', 'FEAT2']\n",
    "y_col1 = 'CASE1'\n",
    "y_col2 = 'CASE2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction for Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR: 0.99949351172687\n",
      "FPR: 0.0\n",
      "FNR: 0.0005064882731302005\n",
      "Prec: 0.940909090909091\n",
      "F1: 0.9671754171754172\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt(m2[X_cols], m2[y_col1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction for Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR: 0.9995946281305311\n",
      "FPR: 0.0\n",
      "FNR: 0.0004053718694688223\n",
      "Prec: 0.9575324675324677\n",
      "F1: 0.9770445344129554\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt(m2[X_cols], m2[y_col2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 11  (LIFNR != SGTXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/software/x86_64/anaconda/envs/anaconda431-py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(96062, 24)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsak = pd.read_csv(join(data_path, 'BSAK.csv'), sep=';', encoding = 'ISO-8859-1')\n",
    "bsak.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cast LIFNR column as string in order to create new column (True if SGTXT text contains LIFNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bsak['LIFNR'] = bsak['LIFNR'].astype(str)\n",
    "bsak['FEAT'] = bsak.apply(lambda x: x.LIFNR  in x.SGTXT, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = list(bsak.select_dtypes(include=['bool', 'int', 'float']).columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select 3 predictor columns and CASE 11 as target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_cols = ['FEAT', 'MONAT', 'BUZEI']\n",
    "y_col = 'CASE11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR: 1.0\n",
      "FPR: 0.0\n",
      "FNR: 0.0\n",
      "Prec: 1.0\n",
      "F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt(bsak[X_cols], bsak[y_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 12 (NAME_TEXTC names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1011, 8)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addr = pd.read_csv(join(data_path, 'USER_ADDR.csv'), sep=';', encoding = 'ISO-8859-1')\n",
    "addr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_names = ['Buchhaltung', 'Lageruser', 'Bachuser-01', 'Bachuser-02', 'Bachuser-03', 'Pr√ºfer', 'Print User', 'Azubi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addr['FEAT'] = addr.apply(lambda x: x.NAME_TEXTC  in wrong_names, axis=1)\n",
    "addr = addr.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_cols = ['FEAT', 'ID_USER']\n",
    "y_col = 'CASE12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR: 1.0\n",
      "FPR: nan\n",
      "FNR: 0.0\n",
      "Prec: 0.2\n",
      "F1: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/software/x86_64/anaconda/envs/anaconda431-py35/lib/python3.5/site-packages/ipykernel/__main__.py:35: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt(addr[X_cols], addr[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:252\n",
      "FN:0\n",
      "TP:1\n",
      "FP:0\n",
      "TPR: 1.0\n",
      "FPR: 0.0\n",
      "FNR: 0.0\n",
      "Prec: 1.0\n",
      "F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "evaluate_dt_split(addr[X_cols], addr[y_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda431-py35]",
   "language": "python",
   "name": "conda-env-anaconda431-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
